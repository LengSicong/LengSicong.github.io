---
permalink: /
title: "About Me"
excerpt: "Welcome to my page!"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

## Introduction
Hello! I'm Sicong Leng, a 3rd-year P.h.D. at Nanyang Technological University supervised by [Prof.Lu Shijian](https://personal.ntu.edu.sg/shijian.lu/) ([Visual-Intelligence Lab](https://sg-vilab.github.io/)/[S-lab](https://www.ntu.edu.sg/s-lab)).
I specialize in Deep Learning with a focus on Multi-modality and Embodied AI research, especially for Vision+Language and Vision+Language+Action.
Feel free to reach out to me for collaborations, questions, or just to chat!

## News
* [25.09] We present **MMR1** with open-sourced [data](https://huggingface.co/MMR1/datasets), [code](https://github.com/LengSicong/MMR1) and [model](https://huggingface.co/MMR1/models)! Check out our paper [here](https://huggingface.co/papers/2509.21268).
* [25.09] 2 papers accepted by **NeurIPS 2025**! [One](https://arxiv.org/abs/2505.22323) is accepted as **oral** paper! Congratulations to the co-authors!
* [25.08] RynnVLA-001 is released! Check out our paper and code [here](https://github.com/alibaba-damo-academy/RynnVLA-001).
* [25.06] Inf-CLIP has received the **CVPR 2025 Highlight**!
* [25.03] MMR1 has been released! Check out our code [here](https://github.com/LengSicong/MMR1).
* [25.03] 2 papers accepted by **CVPR 2025**! Congratulations to the co-authors!
* [25.01] VideoLLaMA 3 has been released! Check out our paper and code [here](https://github.com/DAMO-NLP-SG/VideoLLaMA3).
* [24.10] Inf-CLIP has been released! Check out our project [here](https://github.com/DAMO-NLP-SG/Inf-CLIP?tab=readme-ov-file).
* [24.10] CMM has been released! Check out our project [here](https://cmm-damovl.site).
* [24.09] 1 paper accepted by **NeurIPS 2024**! Congratulations to the co-authors!
* [24.06] VideoLLaMA 2 has been released! Check out our paper and code [here](https://github.com/DAMO-NLP-SG/VideoLLaMA2).
* [24.04] VCD has received the **CVPR 2024 Highlight**!
* [24.03] 3 papers accepted by **CVPR 2024**! Congratulations to the co-authors!
* [23.11] VCD has been released! Check out our paper and code [here](https://github.com/DAMO-NLP-SG/VCD).
* [23.08] We present our work at Nvidia Internal Technical Sharing!
* [23.08] We present our work at AAAI 2023 Summer Symposium Series!
* [23.07] Tell2Design has received the **Area Chair Award** and **Best Paper Nomination** at **ACL 2023**!
* [23.06] Our paper [Tell2Design](https://arxiv.org/abs/2311.15941) has been accepted by **ACL 2023** as a long oral paper!
  
## Awards
* NeurIPS 2025 Oral
* CVPR 2025 Highlight
* CVPR 2024 Highlight
* ACL 2023 Area Chair Award
* ACL 2023 Best Paper Nomination
* ACL 2023 Oral

<!-- red color is used for highlighting  -->
## Selected Publications
* MMR1: Enhancing Multimodal Reasoning with Variance-Aware Sampling and Open Resources [[paper]](https://arxiv.org/abs/2509.21268) [[code]](https://github.com/LengSicong/MMR1) [[data]](https://huggingface.co/MMR1/datasets) [[model]](https://huggingface.co/MMR1/models)
  * **Sicong Leng**\*, Jing Wang\*, Jiaxi Li\*, Hao Zhang\*, Zhiqiang Hu, Boqiang Zhang, Yuming Jiang, Hang Zhang, Xin Li, Lidong Bing, Deli Zhao, Wei Lu, Yu Rong, Aixin Sun, Shijian Lu
  * ArXiv 2025

* VideoLLaMA 3: Frontier Multimodal Foundation Models for Image and Video Understanding [[paper]](https://arxiv.org/abs/2501.13106) [[code]](https://github.com/DAMO-NLP-SG/VideoLLaMA3)
  * Boqiang Zhang\*, Kehan Li\*, Zesen Cheng\*, Zhiqiang Hu\*, Yuqian Yuan\*, Guanzheng Chen\*, **Sicong Leng**\*, Yuming Jiang\*, Hang Zhang\*, Xin Li\*, Peng Jin, Wenqi Zhang, Fan Wang, Lidong Bing, Deli Zhao
  * ArXiv 2025

* Breaking the Memory Barrier: Near Infinite Batch Size Scaling for Contrastive Loss [[paper]](https://arxiv.org/abs/2410.17243) [[code]](https://github.com/DAMO-NLP-SG/Inf-CLIP)
  * Zesen Cheng, Hang Zhang, Kehan Li, **Sicong Leng**, Zhiqiang Hu, Fei Wu, Deli Zhao, Xin Li, Lidong Bing
  * CVPR 2025 $\color{red}{\text{(Highlight)}}$

* The Curse of Multi-Modalities: Evaluating Hallucinations of Large Multimodal Models across Language, Visual, and Audio [[paper]](https://arxiv.org/abs/2410.12787) [[project]](cmm-damovl.site) [[code]](https://github.com/DAMO-NLP-SG/CMM)
  * **Sicong Leng**\*, Yun Xing\*, Zesen Cheng\*, Yang Zhou, Hang Zhang, Xin Li, Deli Zhao, Shijian Lu, Chunyan Miao, Lidong Bing 
  * NeurIPS 2025

* VideoLLaMA 2: Advancing Spatial-Temporal Modeling and Audio Understanding in Video-LLMs [[paper]](https://arxiv.org/abs/2406.07476) [[code]](https://github.com/DAMO-NLP-SG/VideoLLaMA2)
  * Zesen Cheng\*, **Sicong Leng**\*, Hang Zhang\*, Yifei Xin\*, Xin Li\*, Guanzheng Chen, Yongxin Zhu, Wenqi Zhang, Ziyang Luo, Deli Zhao, Lidong Bing
  * ArXiv 2024

* Mitigating Object Hallucinations in Large Vision-Language Models through Visual Contrastive Decoding [[paper]](https://openaccess.thecvf.com/content/CVPR2024/papers/Leng_Mitigating_Object_Hallucinations_in_Large_Vision-Language_Models_through_Visual_Contrastive_CVPR_2024_paper.pdf) [[code]](https://github.com/DAMO-NLP-SG/VCD)
  * **Sicong Leng**\*, Hang Zhang\*, Guanzheng Chen, Xin Li, Shijian Lu, Chunyan Miao, Lidong Bing
  * CVPR 2024 $\color{red}{\text{(Highlight)}}$

* Tell2Design: A Dataset for Language-Guided Floor Plan Generation [[paper]](https://arxiv.org/abs/2311.15941) [[code]](https://github.com/LengSicong/Tell2Design)
  * **Sicong Leng**\*, Yang Zhou\*, Mohammed Haroon Dupty, Wee Sun Lee, Sam Conrad Joyce, Wei Lu
  * ACL 2023 $\color{red}{\text{(Area Chair Award) (Best Paper Nomination)}}$

Please refer to [Google Scholar](https://scholar.google.com/citations?user=xQsBP6YAAAAJ&hl=en) for the full list of publications.

## Service 
* Reviewer:
  * 2025: TPAMI, TMM, NAACL, EMNLP
  * 2024: EMNLP, WACV
  * 2023: EMNLP, CoNLL, NIPS, ACL
* Program Committee:
  * EMNLP 2023 Industry Track

## Work experience
* Aug 2021 - Aug 2023: Research Assistant
  * [StatNLP Lab](https://statnlp-research.github.io/), Singapore University of Technology and Design
  * Research on NLP and Multi-modal Learning
  * Supervisor: Professor [Lu Wei](https://istd.sutd.edu.sg/people/faculty/lu-wei/)


Website last updated on 26th September 2025.

<!-- ## News
  <ul>{% for post in site.talks %}
    {% include archive-single-talk.html %}
  {% endfor %}</ul>

## Publications
  <ul>{% for post in site.publications %}
    {% include archive-single.html %}
  {% endfor %}</ul> -->
